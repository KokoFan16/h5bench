#!/usr/bin/python3

import os
import sys
import json
import time
import uuid
import shlex
import pprint
import errno
import argparse
import collections
import subprocess
import logging
import logging.handlers


class H5bench:
    """H5bench benchmark suite."""

    H5BENCH_PATTERNS_WRITE = 'build/h5bench_write'
    H5BENCH_PATTERNS_READ = 'build/h5bench_read'
    H5BENCH_EXERCISER = 'build/h5bench_exerciser'
    H5BENCH_METADATA = 'build/h5bench_hdf5_iotest'

    def __init__(self, setup, debug):
        """Initialize the suite."""
        self.LOG_FILENAME = '{}-h5bench.log'.format(setup.replace('.json', ''))

        self.configure_log(debug)

        self.setup = setup

    def configure_log(self, debug):
        """Configure the logging system."""
        self.logger = logging.getLogger('H5BENCH')

        if debug:
            self.logger.setLevel(logging.DEBUG)
        else:
            self.logger.setLevel(logging.INFO)

        # Defines the format of the logger
        formatter = logging.Formatter('%(asctime)s %(module)s - %(levelname)s - %(message)s')

        # Configure the log rotation
        handler = logging.handlers.RotatingFileHandler(
            self.LOG_FILENAME,
            maxBytes=268435456,
            backupCount=50,
            encoding='utf8'
        )

        handler.setFormatter(formatter)

        self.logger.addHandler(handler)

        if debug:
            console = logging.StreamHandler()
            
            console.setFormatter(formatter)

            self.logger.addHandler(console)        

    def prepare(self, directory):
        """Create a temporary directory to store all the results of the benchmark."""
        self.directory = directory

        try:
            # Create a temporary directory to store all configurations
            os.mkdir(directory)
        except OSError as exc:
            if exc.errno != errno.EEXIST:
                raise

            self.logger.warning('Base directory already exists: {}'.format(directory))

            pass
        except Exception as e:
            self.logger.debug('Unable to create {}: {}'.format(directory, e))

    def run(self):
        """Run all the benchmarks/kernels."""
        self.logger.info('Starting h5bench Suite')

        try:
            with open(self.setup) as file:
                setup = json.load(file, object_pairs_hook=collections.OrderedDict)
        except Exception as e:
            self.logger.critical('Unable to find and parse the input configuration file')

            exit(-1)

        self.prepare(setup['directory'])

        benchmarks = setup['benchmarks']

        for benchmark in benchmarks:
            name = next(iter(benchmark))
            id =  str(uuid.uuid4()).split('-')[0]
            
            self.logger.info('h5bench [{}] - Starting'.format(name))
            self.logger.info('h5bench [{}] - DIR: {}/{}/'.format(name, setup['directory'], id))

            os.mkdir('{}/{}'.format(setup['directory'], id))

            self.prepare_parallel(setup['mpi'])

            if name == 'write':
                self.run_pattern(id, name, benchmark[name])
            elif name == 'read':
                self.run_pattern(id, name, benchmark[name])
            elif name == 'exerciser':
                self.run_exerciser(id, benchmark[name])
            elif name == 'metadata':
                self.run_metadata(id, benchmark[name])
            else:
                self.logger('{} - Unsupported benchmark/kernel')

            self.logger.info('h5bench [{}] - Complete'.format(name))

        self.logger.info('Finishing h5bench Suite')

    def prepare_parallel(self, mpi):
        """Prepare the MPI launch command."""
        if mpi['command'] in ['mpirun', 'mpiexec']:
            self.mpi = '{} -np {}'.format(mpi['command'], mpi['ranks'])
        elif mpi['command'] == 'srun':
            self.mpi = '{} --cpu_bind=cores -n {}'.format(mpi['command'], mpi['ranks'])
        else:
            self.logger.warning('Unknown MPI launcher selected!')

            self.mpi = ''

    def run_pattern(self, id, operation, setup):
        """Run the h5bench_patterns (write/read) benchmarks."""
        try:
            start = time.time()

            # Define the output file (should be a .h5 file)
            file = '{}/{}'.format(self.directory, setup['file'])
            configuration = setup['configuration']

            configuration_file = '{}/{}/h5bench.cfg'.format(self.directory, id)

            # Create the configuration file for this benchmark
            with open(configuration_file, 'w+') as f:
                for key in configuration:
                    # Make sure the CSV file is generated in the temporary path
                    if key == 'CSV_FILE':
                        configuration[key] = '{}/{}/{}'.format(self.directory, id, configuration[key])

                    f.write('{}={}\n'.format(key, configuration[key]))

            if operation == 'write':
                benchmark_path = self.H5BENCH_PATTERNS_WRITE

            if operation == 'read':
                benchmark_path = self.H5BENCH_PATTERNS_READ

            command = '{} {} {} {}'.format(
                self.mpi,
                benchmark_path,
                configuration_file,
                file
            )

            self.logger.info(command)

            # Make sure the command line is in the correct format
            arguments = shlex.split(command)

            stdout_file_name = '{}/{}/stdout'.format(self.directory, id)
            stderr_file_name = '{}/{}/stderr'.format(self.directory, id)
            
            with open(stdout_file_name, mode='w') as stdout_file, open(stderr_file_name, mode='w') as stderr_file:
                s = subprocess.Popen(arguments, stdout=stdout_file, stderr=stderr_file)
                sOutput, sError = s.communicate()
            
                if s.returncode == 0:
                    self.logger.info('SUCCESS')
                else:
                    self.logger.error('Return: %s', s.returncode)

            end = time.time()

            self.logger.info('Runtime: {} seconds (elapsed time, includes allocation wait time)'.format(end - start))
        except Exception as e:
            self.logger.error('Unable to run the benchmark: %s', e)

    def run_exerciser(self, id, setup):
        """Run the exerciser benchmark."""
        try:
            start = time.time()

            configuration = setup['configuration']

            parameters = []

            # Create the configuration parameter list
            for key in configuration:
                parameters.append('--{} {} '.format(key, configuration[key]))

            command = '{} {} {}'.format(
                self.mpi,
                self.H5BENCH_EXERCISER,
                ' '.join(parameters)
            )

            self.logger.info(command)

            # Make sure the command line is in the correct format
            arguments = shlex.split(command)

            stdout_file_name = '{}/{}/stdout'.format(self.directory, id)
            stderr_file_name = '{}/{}/stderr'.format(self.directory, id)
            
            with open(stdout_file_name, mode='w') as stdout_file, open(stderr_file_name, mode='w') as stderr_file:
                s = subprocess.Popen(arguments, stdout=stdout_file, stderr=stderr_file)
                sOutput, sError = s.communicate()
            
                if s.returncode == 0:
                    self.logger.info('SUCCESS')
                else:
                    self.logger.error('Return: %s', s.returncode)

            end = time.time()

            self.logger.info('Runtime: {} seconds (elapsed time, includes allocation wait time)'.format(end - start))
        except Exception as e:
            self.logger.error('Unable to run the benchmark: %s', e)

    def run_metadata(self, id, setup):
        """Run the metadata stress benchmark."""
        try:
            start = time.time()

            # Define the output file (should be a .h5 file)
            file = '{}/{}'.format(self.directory, setup['file'])
            configuration = setup['configuration']

            configuration_file = '{}/{}/hdf5_iotest.ini'.format(self.directory, id)

            # Create the configuration file for this benchmark
            with open(configuration_file, 'w+') as f:
                for key in configuration:
                    # Make sure the CSV file is generated in the temporary path
                    if key == 'csv-file':
                        configuration[key] = '{}/{}/{}'.format(self.directory, id, configuration[key])

                    f.write('{} = {}\n'.format(key, configuration[key]))

                f.write('hdf5-file = {}\n'.format(file))

            command = '{} {} {} {}'.format(
                self.mpi,
                self.H5BENCH_METADATA,
                configuration_file,
                file
            )

            self.logger.info(command)

            # Make sure the command line is in the correct format
            arguments = shlex.split(command)

            stdout_file_name = '{}/{}/stdout'.format(self.directory, id)
            stderr_file_name = '{}/{}/stderr'.format(self.directory, id)
            
            with open(stdout_file_name, mode='w') as stdout_file, open(stderr_file_name, mode='w') as stderr_file:
                s = subprocess.Popen(arguments, stdout=stdout_file, stderr=stderr_file)
                sOutput, sError = s.communicate()
                        
                if s.returncode == 0:
                    self.logger.info('SUCCESS')
                else:
                    self.logger.error('Return: %s', s.returncode)

            end = time.time()

            self.logger.info('Runtime: {} seconds (elapsed time, includes allocation wait time)'.format(end - start))
        except Exception as e:
            self.logger.error('Unable to run the benchmark: %s', e)


PARSER = argparse.ArgumentParser(
    description='H5bench: a Parallel I/O Benchmark Suite for HDF5: '
)

PARSER.add_argument(
    '--setup',
    action='store',
    dest='setup',
    required=True,
    help='JSON file with the benchmarks to run'
)

PARSER.add_argument(
    '--debug',
    action='store_true',
    dest='debug',
    help='Enable debug mode'
)

ARGS = PARSER.parse_args()

BENCH = H5bench(ARGS.setup, ARGS.debug)
BENCH.run()
